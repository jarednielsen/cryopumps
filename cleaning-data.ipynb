{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cryogenic Pump Cleaning Data\n",
    "### Jared Nielsen\n",
    "\n",
    "\n",
    "## Out-of-Memory Errors\n",
    "The `client.csv` files are 1.8GB (14 million rows x 38 cols), 1.2GB, and a few hundred KB, respectively.  \n",
    "For comparison, `QSS Data Share.csv` is 200MB. Pandas crashes when I load the files, so we might need a better system.  \n",
    "A 100k-row CSV takes 1.2 seconds, a 1-million row CSV takes 12 seconds to load, and it appears to scale linearly.  \n",
    "An out-of-memory error is thrown when loading a 14-million row CSV.  \n",
    "\n",
    "## Chunking & Intermediate Cleaning\n",
    "So we load the data in 100,000-row chunks, clean and separate the chunks, and append to a CSV file. This reduces RAM usage.  \n",
    "After saving the intermediate cleaned data, we then load the smaller CSV as a single Pandas dataframe and finish processing it.  \n",
    "- Merge the `unitsequence` with the `dsname`, or pump type.  \n",
    "- Separate into cryos and turbos, and keep only the relevant fields.\n",
    "- Save the intermediate smaller dataframes by appending chunks one at a time.\n",
    "\n",
    "## Final Cleaning & Saving\n",
    "- Remove the duplicate `ID` field.\n",
    "- Upsample from milliseconds up to minutes.\n",
    "- Remove duplicate minutes on the same pump.\n",
    "- Save the entire dataframe into the final cleaned data CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 15,3\n",
    "blue = '#1f77b4'\n",
    "pd.set_option('precision', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# CSVs to load. For simplicity, we will just work with the first one initially. It's plenty big.\n",
    "filenames = [\n",
    "    '20180814_102020_DMOS6_0_client.csv',\n",
    "    '20180814_102020_DMOS6_0_unit.csv',\n",
    "    '20181105_130901_DMOS6_0_client.csv',\n",
    "    '20181105_130901_DMOS6_0_unit.csv',\n",
    "    '20181105_131740_DMOS6_0_client.csv',\n",
    "    '20181105_131740_DMOS6_0_unit.csv'\n",
    "]\n",
    "folder = '/mnt/pccfs/backed_up/tcs/Archive/'\n",
    "url_client = folder+filenames[0]\n",
    "url_unit = folder+filenames[1]\n",
    "\n",
    "# Declare datatypes (strings/floats) for each field in the CSV.\n",
    "dtype = {\n",
    "    \"unitsequence\": int, # ID, negative is test, positive is production\n",
    "    \"uppervalue\": float, # turbo vibrations\n",
    "    \"lowervalue\": float,\n",
    "    \"rotorspeed\": float, # turbo speed\n",
    "    \"motortemp\": float, # turbo\n",
    "    \"controllertemp\": float, # turbo\n",
    "    \"dcvoltage\": float, # turbo\n",
    "    \"motorcurrent\": float, # turbo\n",
    "    \"rotorposition0\": str, # turbo, positions of the sensors that determine vibration\n",
    "    \"rotorposition1\": str,\n",
    "    \"rotorposition2\": str,\n",
    "    \"rotorposition3\": str,\n",
    "    \"rotorposition4\": str,\n",
    "    \"magcurrent0\": float, # turbo balancing factors\n",
    "    \"magcurrent1\": float, # 0-7 should all be symmetrical\n",
    "    \"magcurrent2\": float,\n",
    "    \"magcurrent3\": float,\n",
    "    \"magcurrent4\": float,\n",
    "    \"magcurrent5\": float,\n",
    "    \"magcurrent6\": float,\n",
    "    \"magcurrent7\": float,\n",
    "    \"magcurrent8\": float, # last two are on top\n",
    "    \"magcurrent9\": float,\n",
    "    \"sumcurrents\": float, # sum of them\n",
    "    \"tmsactualtemp\": float, # turbo heating system temperature. -80 means \"NaN\"\n",
    "    \"yh\": str, # Alcatel turbo, replacement for `rotorposition0`.\n",
    "    \"yb\": str,\n",
    "    \"z\": float,\n",
    "    # CRYO fields\n",
    "    \"motorspeed\": str, # cryos\n",
    "    \"temp1\": float, # cryos, target 65\n",
    "    \"temp2\": float, # cryos, target 9/11\n",
    "    \"heater1\": float,\n",
    "    \"heater2\": float,\n",
    "    \"tcpressure\": float, # thermocouple gauge pressure, cryo\n",
    "    \"timestamp\": str,\n",
    "    \"currentregen\": str, # letter codes\n",
    "    \"alarmstatusbits\": str, # \n",
    "    \"alertstatusbits\": str,\n",
    "    \"valvestate\": str\n",
    "}\n",
    "\n",
    "# Load the key, which maps pump IDs to their type.\n",
    "x_unit = pd.read_csv(url_unit)\n",
    "\n",
    "parse_dates = ['timestamp']\n",
    "start = datetime.now()\n",
    "x_client_chunks = pd.read_csv(url_client, dtype=dtype, parse_dates=parse_dates, chunksize=100000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: Possibly include rotorspeed in the cryo. It's present in some but not all.\n",
    "cryo_cols = ['unitsequence', 'timestamp', 'temp1', 'temp2', \n",
    "             'heater1', 'heater2', 'tcpressure', 'currentregen']\n",
    "cryo_vals = ['temp1', 'temp2', 'heater1', 'heater2', 'tcpressure']\n",
    "# TODO: Possibly include the magcurrents in the turbo.\n",
    "turbo_cols = ['unitsequence', 'timestamp', 'uppervalue', 'lowervalue', 'rotorspeed', \n",
    "              'controllertemp', 'dcvoltage', 'motorcurrent']\n",
    "turbo_vals = turbo_cols[2:]\n",
    "\n",
    "\n",
    "def clean_chunk(x_unit, x_client):\n",
    "    x_client_deduplicate = x_client.drop_duplicates(subset=['unitsequence', 'timestamp'], keep='first')\n",
    "    x_merge = pd.merge(x_client_deduplicate, x_unit, on='unitsequence')\n",
    "    x_cryo = x_merge[x_merge['dsname'] == 'CRYO'][cryo_cols]\n",
    "    x_turbo = x_merge[x_merge['dsname'] == 'SCU'][turbo_cols]\n",
    "    \n",
    "    return x_cryo, x_turbo\n",
    "\n",
    "cryo_dfs = []\n",
    "turbo_dfs = []\n",
    "for i, chunk in enumerate(x_client_chunks):\n",
    "#     print(\"chunk {}\".format(i))\n",
    "    x_cryo, x_turbo = clean_chunk(x_unit, chunk)\n",
    "    cryo_dfs.append(x_cryo)\n",
    "    turbo_dfs.append(x_turbo)\n",
    "    \n",
    "# print(len(cryo_dfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryos_csv_duplicates = 'cryos_cleaned_temp.csv'\n",
    "turbos_csv_duplicates = 'turbos_cleaned_temp.csv'\n",
    "\n",
    "for i, cryo_df in enumerate(cryo_dfs):\n",
    "    header = True if i == 0 else False\n",
    "    cryo_df.to_csv(cryos_csv_duplicates, mode='a', header=header) # takes an exorbitant amount of time\n",
    "    \n",
    "for i, turbo_df in enumerate(turbo_dfs):\n",
    "    header = True if i == 0 else False\n",
    "    turbo_df.to_csv(turbos_csv_duplicates, mode='a', header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cryos Shape: (2005273, 8)\n",
      "Time: 9.792932\n",
      "Turbos Shape: (409653, 8)\n",
      "Time: 9.774025\n"
     ]
    }
   ],
   "source": [
    "def clean(df):\n",
    "    df = df.drop(\"Unnamed: 0\", axis='columns',) # remove previous 'ID' field\n",
    "    df.loc[:,'timestamp'] = df.loc[:,'timestamp'].astype('datetime64[m]') # upsample to nearest minute\n",
    "    df = df.drop_duplicates(subset=['unitsequence', 'timestamp'], keep='first') # deduplicate\n",
    "    return df\n",
    "\n",
    "cryo_csv = 'cryos_cleaned.csv'\n",
    "turbo_csv = 'turbos_cleaned.csv'\n",
    "\n",
    "start = datetime.now()\n",
    "x_cryo = clean(pd.read_csv(cryos_csv_duplicates))\n",
    "elapsed = (datetime.now() - start).total_seconds()\n",
    "\n",
    "print(\"Cryos Shape: {}\".format(x_cryo.shape))\n",
    "print(\"Time: {}\".format(elapsed))\n",
    "\n",
    "start = datetime.now()\n",
    "x_turbo = clean(pd.read_csv(turbos_csv_duplicates))\n",
    "elapsed = (datetime.now() - start).total_seconds()\n",
    "\n",
    "print(\"Turbos Shape: {}\".format(x_turbo.shape))\n",
    "print(\"Time: {}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is Clean!\n",
      "Stored in cryos_cleaned.csv and turbos_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "x_cryo.to_csv(cryo_csv, header=True, index=False)\n",
    "x_turbo.to_csv(turbo_csv, header=True, index=False)\n",
    "print(\"Data is Clean!\")\n",
    "print(\"Stored in {} and {}\".format(cryo_csv, turbo_csv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
